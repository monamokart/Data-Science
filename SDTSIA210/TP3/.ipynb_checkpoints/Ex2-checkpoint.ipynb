{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iafPdtuncbq7"
   },
   "source": [
    "<h1><center>MNIST classification using Keras<center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I4VrCB5La5rD"
   },
   "source": [
    "# Importing Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OlKZ3Hnas7B4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using tensorflow version 2.4.1\n",
      "Using keras version 2.4.3\n"
     ]
    }
   ],
   "source": [
    "# Importing the Keras main module forcing tensorflow 1.x backend\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "print(\"Using tensorflow version \" + str(tf.__version__))\n",
    "print(\"Using keras version \" + str(keras.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s_QLz9_jbRZq"
   },
   "source": [
    "## Loading and preparing the MNIST dataset\n",
    "\n",
    "Again, load the dataset via ```keras.datasets```, turn train and test labels into one-hot encoding, and reshape and normalize data as in the first exercise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "gG83hGyVmijn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set : (60000, 28, 28)\n",
      "Size of testing set : (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "# START CODE HERE\n",
    "(train_images, y_train),(test_images, y_test) = mnist.load_data()\n",
    "print(\"Size of training set :\", train_images.shape)\n",
    "print(\"Size of testing set :\", test_images.shape)\n",
    "n_train = train_images.shape[0]\n",
    "n_test = test_images.shape[0]\n",
    "\n",
    "# END CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lQbkllF8mnaf"
   },
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "# START CODE HERE\n",
    "train_labels = to_categorical(y_train, 10)\n",
    "test_labels = to_categorical(y_test, 10)\n",
    "# END CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ptTRSDo5nJyZ"
   },
   "outputs": [],
   "source": [
    "# Reshape to proper images with 1 color channel according to backend scheme\n",
    "img_rows, img_cols = train_images.shape[1], train_images.shape[2]\n",
    "\n",
    "# START CODE HERE\n",
    "train_images = train_images.reshape((n_train, img_rows*img_cols))\n",
    "test_images = test_images.reshape((n_test, img_rows*img_cols))\n",
    "# END CODE HERE\n",
    "\n",
    "# Cast pixels from uint8 to float32\n",
    "train_images = train_images.astype('float32')\n",
    "\n",
    "# Now let us normalize the images so that they have zero mean and standard deviation\n",
    "# Hint: are real testing data statistics known at training time ?\n",
    "# START CODE HERE\n",
    "...\n",
    "# END CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lnKYaP-KVoOs"
   },
   "source": [
    "## Defining the neural network architecture (i.e., the network model)\n",
    "\n",
    "You can take a look at this [cheatsheet](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Keras_Cheat_Sheet_Python.pdf) for some basic commands to use keras.\n",
    "\n",
    "First, try to replicate the classifier of the first exercise. Secondly, create a fully connected network.\n",
    "For the fully connected layer, you can for example use this architecture: \n",
    "$$ (784) \\rightarrow (300) \\rightarrow (10) $$\n",
    "For this first implementation of the network, use only sigmoid activations in the hidden layer. Remember to use the right output activation function ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pnd3q1V3nk8v"
   },
   "outputs": [],
   "source": [
    "# The Sequential module is a container for more complex NN elements and\n",
    "# defines a loop-less NN architecture\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "\n",
    "# START CODE HERE\n",
    "input_shape = ...\n",
    "output_shape = ...\n",
    "...\n",
    "# END CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7g2PNEiwWBLw"
   },
   "source": [
    "Instantiate a SGD optimizer with a tentative learning rate of $\\\\eta = 10^{-2}$ and, using the appropriate loss function (which is called, in keras, ```'categorical_crossentropy'```) and compile the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SijGZGKjV9J2",
    "outputId": "ae6c8734-e7ec-46e7-f019-6711f5980c67"
   },
   "outputs": [],
   "source": [
    "# The optimizers module provides a number of optimization algorithms for updating\n",
    "# a netwok parameters accoridng to the computed error gradints\n",
    "from keras import optimizers\n",
    "\n",
    "# START CODE HERE\n",
    "...\n",
    "# END CODE HERE\n",
    "# We can now have a look at the defined model topology\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u-WqMtSAWTRp"
   },
   "source": [
    "## Training the network\n",
    "\n",
    "Train the model for 10 epochs using the ```.fit()``` method, validating the model at each epoch and keeping track of the training history for later plotting. Make sure you enable ```.fit()``` verbose mode in order to visualize the training.\n",
    "\n",
    "In order to accelerate training, use the ```batch_size``` option of ```.fit()```, which will process a batch of examples at the same time, and make one update for all of them, averaged over the gradients for each training example of the batch. You can begin with a small size, and experiment with a larger size later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gTHrbb7uFYWz"
   },
   "outputs": [],
   "source": [
    "# This is where the actual training-testing happens\n",
    "# Number of epochs we want to train\n",
    "epochs = 10\n",
    "\n",
    "# START CODE HERE\n",
    "...\n",
    "# END CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ODUc5Bq_dMEq"
   },
   "source": [
    "## Visualizing the network performance\n",
    "\n",
    "Visualize the training history using the ```pyplot``` package:\n",
    "- In one graph, plot the train and vaidation loss functions,\n",
    "- In another graph, the train and validation accuracy.\n",
    "By comparing the training the testing curves, what can we conclude about the quality of the training ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QdJrRbyariEw"
   },
   "outputs": [],
   "source": [
    "# We now want to plot the train and validation loss functions and accuracy curves\n",
    "#print(history.history.keys())\n",
    "\n",
    "# summarize history for loss\n",
    "# START CODE HERE\n",
    "...\n",
    "# END CODE HERE\n",
    "plt.show()\n",
    "\n",
    "# summarize history for accuracy\n",
    "# START CODE HERE\n",
    "...\n",
    "# END CODE HERE\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nr4TdWoEoDzi"
   },
   "source": [
    "## Experiments\n",
    "\n",
    "Note down the performance of the larger network in terms of training and validation accuracy as a reference (save the loss/accuracy graphs of the network).\n",
    "\n",
    "Then, experiment as follow and compare performance with the reference scenario:\n",
    "\n",
    "*  Experiment increasing the size of the batch and compare the performance with reference.\n",
    "*  Experiment replacing the sigmoid activations with Relus and note what happens.\n",
    "*  Experiment with a larger architecture, for example: \n",
    "$$ (784) \\rightarrow (300) \\rightarrow (128) \\rightarrow (84) \\rightarrow (10) $$"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TP4_1_empty.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
